# HookedOnCode Environment Variables
# Copy this to your ~/.bashrc, ~/.zshrc, or shell profile

# OpenRouter API Configuration (for code_suggestions_hook.py)
export OPENROUTER_API_KEY="your-api-key-here"  # Get from https://openrouter.ai/keys
export OPENROUTER_MODEL="x-ai/grok-code-fast-1"  # Optional, defaults to Grok Code Fast

# LM Studio Configuration (for local LLM models)
export LM_STUDIO_HOST="http://localhost:1234"  # Optional, defaults to localhost:1234
export LM_STUDIO_MODEL="nousresearch/hermes-4-70b"  # Optional, has default
export SWALLOWMAID_MODEL="swallowmaid-8b-l3-sppo-abliterated@q8_0"  # For sexy_code_hook.py

# Ollama Configuration (alternative to LM Studio)
export OLLAMA_HOST="http://localhost:11434"  # Optional, defaults to localhost:11434
export OLLAMA_MODEL="codellama:7b"  # Optional, defaults to CodeLlama

# Service Selection (choose which backend to use)
export CODE_HOOK_SERVICE="openrouter"  # Options: openrouter, lm_studio, ollama
